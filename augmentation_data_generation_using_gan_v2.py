# -*- coding: utf-8 -*-
"""Augmentation_data_generation_using_GAN_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V8cexcK7Eq2wOpXYJUwva-sKhxCTPX7i
"""

!pip install torch torchvision

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms
from torchvision.utils import save_image
import os
from PIL import Image  # Import PIL for loading images

# Generator model (modified for color images)
class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Linear(1024, 3 * 64 * 64),  # Adjusted for RGB (3 channels) and 64x64 resolution
            nn.Tanh()  # Output between [-1, 1]
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), 3, 64, 64)  # Adjust for RGB images
        return img

# Discriminator model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(3 * 64 * 64, 512),  # Adjusted for RGB images (3 channels)
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()  # Output between [0, 1]
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity

# Hyperparameters
latent_dim = 100
batch_size = 16
lr = 0.0002
num_epochs = 100
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Custom Dataset for loading a single folder of images
class SingleFolderDataset(Dataset):
    def __init__(self, folder_path, transform=None):
        self.folder_path = folder_path
        self.image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.folder_path, self.image_files[idx])
        image = Image.open(img_path).convert('RGB')  # Ensure the image is loaded as RGB
        if self.transform:
            image = self.transform(image)
        return image

# Image transformations (for RGB images)
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # Resize to 64x64
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize for RGB
])

# Load the data from a specific folder
data_dir = '/content/drive/MyDrive/org_split_data/train/cluster_0'
dataset = SingleFolderDataset(folder_path=data_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Initialize Generator and Discriminator
generator = Generator(latent_dim).to(device)
discriminator = Discriminator().to(device)

# Optimizers and Loss function
optimizer_G = optim.Adam(generator.parameters(), lr=lr)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)
adversarial_loss = nn.BCELoss()

# Training loop
def train_dcgan(generator, discriminator, dataloader, num_epochs):
    for epoch in range(num_epochs):
        for i, imgs in enumerate(dataloader):  # Unpack only the images
            # Train Discriminator
            real_imgs = imgs.to(device)
            valid = torch.ones((real_imgs.size(0), 1), requires_grad=False).to(device)
            fake = torch.zeros((real_imgs.size(0), 1), requires_grad=False).to(device)

            optimizer_D.zero_grad()
            real_loss = adversarial_loss(discriminator(real_imgs), valid)
            z = torch.randn((real_imgs.size(0), latent_dim)).to(device)
            gen_imgs = generator(z)
            fake_loss = adversarial_loss(discriminator(gen_imgs), fake)
            d_loss = (real_loss + fake_loss) / 2
            d_loss.backward()
            optimizer_D.step()

            # Train Generator
            optimizer_G.zero_grad()
            z = torch.randn((real_imgs.size(0), latent_dim)).to(device)
            gen_imgs = generator(z)
            g_loss = adversarial_loss(discriminator(gen_imgs), valid)
            g_loss.backward()
            optimizer_G.step()

        print(f"Epoch [{epoch}/{num_epochs}] - D loss: {d_loss.item():.4f}, G loss: {g_loss.item():.4f}")

        # Save generated images
        if epoch % 10 == 0:
            save_image(gen_imgs.data[:25], f'generated_images_epoch_{epoch}.png', nrow=5, normalize=True)

# Call the training function
train_dcgan(generator, discriminator, dataloader, num_epochs)

# Function to generate new images
def generate_new_images(generator, num_images, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    generator.eval()

    with torch.no_grad():
        for i in range(num_images):
            z = torch.randn(1, latent_dim).to(device)
            gen_img = generator(z)
            save_image(gen_img, os.path.join(save_dir, f'generated_image_{i}.png'), normalize=True)
            print(f"Generated image {i+1}/{num_images}")

# Generate 50 new images for the underrepresented class
generate_new_images(generator, 50, '/content/drive/MyDrive/augmented-images/cluster-0')

