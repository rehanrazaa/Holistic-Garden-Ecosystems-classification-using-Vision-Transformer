# -*- coding: utf-8 -*-
"""Augmentation_data_generation_using_GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wov7TmnwEp-OiPusVneIJu5KpMZilf-N
"""

!pip install torch torchvision

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import save_image
import os

class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Linear(1024, 28*28),
            nn.Tanh()  # Output between [-1, 1]
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), 1, 28, 28)
        return img

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()  # Output between [0, 1]
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity

## not working
class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128 * 7 * 7),
            nn.ReLU(True),
            nn.BatchNorm1d(128 * 7 * 7),
            nn.Unflatten(1, (128, 7, 7)),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(True),
            nn.BatchNorm2d(64),
            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )

    def forward(self, z):
        return self.model(z)

##not working
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Flatten(),
            nn.Linear(128 * 7 * 7, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        return self.model(img)

latent_dim = 100
batch_size = 16
lr = 0.0002
num_epochs = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Custom Dataset for a single folder of images
from torch.utils.data import Dataset, DataLoader
class SingleFolderDataset(Dataset):
    def __init__(self, folder_path, transform=None):
        self.folder_path = folder_path
        self.image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.folder_path, self.image_files[idx])
        image = Image.open(img_path)
        if self.transform:
            image = self.transform(image)
        return image

# Image transformations
transform = transforms.Compose([
    transforms.Resize((28, 28)),  # Resize to match the model
    transforms.Grayscale(),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Load the data from specific folder
data_dir = '/content/drive/MyDrive/org_split_data/train/cluster_0'  # Specify the folder for classes with less images


#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

dataset = SingleFolderDataset(folder_path=data_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

def train_dcgan(generator, discriminator, dataloader, num_epochs):
    for epoch in range(num_epochs):
        for i, imgs in enumerate(dataloader):  # Unpack only the images

            # Train Discriminator
            real_imgs = imgs.to(device)  # No need for labels, just images
            valid = torch.ones((real_imgs.size(0), 1), requires_grad=False).to(device)
            fake = torch.zeros((real_imgs.size(0), 1), requires_grad=False).to(device)

            optimizer_D.zero_grad()
            real_loss = adversarial_loss(discriminator(real_imgs), valid)
            z = torch.randn((real_imgs.size(0), latent_dim)).to(device)
            gen_imgs = generator(z)
            fake_loss = adversarial_loss(discriminator(gen_imgs), fake)
            d_loss = (real_loss + fake_loss) / 2
            d_loss.backward()
            optimizer_D.step()

            # Train Generator
            optimizer_G.zero_grad()
            z = torch.randn((real_imgs.size(0), latent_dim)).to(device)
            gen_imgs = generator(z)
            g_loss = adversarial_loss(discriminator(gen_imgs), valid)
            g_loss.backward()
            optimizer_G.step()

        print(f"Epoch [{epoch}/{num_epochs}] - D loss: {d_loss.item():.4f}, G loss: {g_loss.item():.4f}")

        # Save generated images
        if epoch % 10 == 0:
            save_image(gen_imgs.data[:25], f'generated_images_epoch_{epoch}.png', nrow=5, normalize=True)

# Call the training function
train_dcgan(generator, discriminator, dataloader, num_epochs)

def generate_new_images(generator, num_images, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    generator.eval()

    with torch.no_grad():
        for i in range(num_images):
            z = torch.randn(1, latent_dim).to(device)
            gen_img = generator(z)
            save_image(gen_img, os.path.join(save_dir, f'generated_image_{i}.png'), normalize=True)
            print(f"Generated image {i+1}/{num_images}")

# Generate 50 new images for the underrepresented class
generate_new_images(generator, 50, '/content/drive/MyDrive/augmeted-images/cluster-0')

